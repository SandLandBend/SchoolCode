\documentclass[12pt,a4paper,oneside]{article}

%################################# Preamble ##################################%

	%%%%%%%%%%%%%%%%%  << MATLAB INCLUSION>>  %%%%%%%%%%%%%%%%%
	\usepackage[]{mcode}
	% *mcode is in 
	%		/Users/zachdischner/Library/texmf/tex/latex/local
	% added to database with:
	%    		>>> sudo texhash
	%%%%%%%%%%%%%%%%%  << MATLAB INCLUSION>>  %%%%%%%%%%%%%%%%%
	
	%%%%%%%%%%%%%%%%%  << Margins and Spacing>>  %%%%%%%%%%%%%%%%%
	\usepackage[margin=0.75in]{geometry}
	%%%%%%%%%%%%%%%%%  << Margins and Spacing>>  %%%%%%%%%%%%%%%%%
	
	%%%%%%%%%%%%%%%%%  << IMAGE INCLUSION>>  %%%%%%%%%%%%%%%%%
	\usepackage{graphicx}
	%%%%%%%%%%%%%%%%%  << IMAGE INCLUSION>>  %%%%%%%%%%%%%%%%%


	\usepackage{natbib}
	\usepackage{color}
	\usepackage{cleveref}
	\usepackage{amsmath}
		\numberwithin{equation}{section}   		% Make EQ labeling count with section		(2.1)
		%\numberwithin{equation}{subsection}    % Make EQ labeling count with subsection       (2.3.1)
	\usepackage{graphicx}
	\usepackage{color}
	\usepackage{appendix}
	\usepackage{url}
	
	\usepackage{float}
	%\floatstyle{boxed} 		% Box around figures and things
	\restylefloat{figure}
	\setlength{\textfloatsep}{15pt plus 1.0pt minus 2.0pt}
	\setlength{\floatsep}{5pt plus 1.0pt minus 2.0pt}
	
	% Other packages
	%\usepackage{times, rawfonts, geometry}
	%\usepackage{amsmath,amssymb}
	%\usepackage{float}
	
	% New commands
	\newcommand{\ignore}[1]{}  % {} empty inside = %% comment
	
	% Editing
	\newcommand{\bad}[1]{\color{red}\textbf{#1}\color{black}}
	
	% Scientific notation:
	\providecommand{\e}[1]{\ensuremath{\times 10^{#1}}}
	
	% General
	\newcommand{\parens} [1] {\left(  #1  \right)}
	\newcommand{\brackets} [1] {\left[ #1 \right]}
	\newcommand{\rootdir}{./Figures/}
	
	% Array
	\newcommand{\arrayp}[2]{\parens{ \begin{array}{#1}  #2 \end{array} } }
	\newcommand{\arrayb}[2]{\brackets{ \begin{array}{#1}  #2 \end{array} } }
	% Use like:  where {c|c} is a vertical bar, inserts into the matrix. 
	% $\arrayb{c|c}{y & 4\\y & 4\\y & X\\y & nn}$
	
	%Figure {HERE}   - use like:  \fig{figurename.extension}{Caption}{Label}
	\newcommand{\fig}[3]{
			\begin{center}
				\begin{figure}[H]
					\includegraphics[width=.9\textwidth]{\rootdir #1}
					\caption{#2}
					\label{#3}
				\end{figure}
			\end{center}
			}
	

%################################# Preamble ##################################%

\begin{document}

\title{ASEN 5070-Stastistical Orbit Determination-Final Project Report}
\author{Zach Dischner \\ University of Colorado at Boulder \\ Department of Aerospace Engineering}
\date{12-2-2012}
\maketitle

\begin{center}
	\begin{figure}[H]
		\includegraphics[width=.9\textwidth]{\rootdir GPS.jpg}    \cite{GPS}
	\end{figure}
\end{center}


\newpage
% Introduction
%----------------------------------------------------------------------------------------------------------------------------------------
\section{Introduction}
This report summarizes an investigation of various methods of statistical orbit determination, as outlined in ASEN 5070. All programming was performed in Matlab, using a combination of built in functions,  self-defined functions, and ones created in collaboration with others. I will examine the results and implications of various filter methodologies including:

\begin{itemize}
	\renewcommand{\labelitemi}{$\bullet$}
	\item Batch Processor
	\item Conventional Kalman (Sequential) Filter
	\item Extended Kalman Filter
	\item State Noise Compensation
	\item Alternative Methods for Determining \emph{P}, the Covariance Matrix
\end{itemize}

Henceforth, any mention of \emph{textbook, 5070 textbook} or simply, \emph{the book} will refer to the text written by Byron D. Tapley, Bob E. Schutz,  and George H Born, titled "Statistical Orbit Determination" \cite{tapley2004statistical}.  All equations, methodologies, and definitions were obtained from this text\footnote{Unless otherwise mentioned, all equations are from this text and will not be sited individually}.
%----------------------------------------------------------------------------------------------------------------------------------------


\newpage
% Table Of Contents
%----------------------------------------------------------------------------------------------------------------------------------------
\tableofcontents{}
\listoffigures{}
%----------------------------------------------------------------------------------------------------------------------------------------


\newpage
% Background
%----------------------------------------------------------------------------------------------------------------------------------------
\section{Background}

\subsection{Orbit Determination Process}
\label{sec:OD Process}

%----------------------------------------------------
%----------------------------------------------------
%Overview--------------------------------------------------------------

\subsubsection{Overview of Orbit Determination Process}
\label{sec:OD sub Overview}
The orbit determination process is, at the fundamental level, one which determines a celestial body's motion relative to another. Typically, this process is used to determine the motion of Earth-launched satellites relative to Earth. Though the problem can and is often applied to a variety of systems, but this paper will concern itself with Earth-centered satellites and their dynamical states. Even so, the same process described here can easily be applied to any dynamical system. From tracking trains and automobiles, to basic control systems for pointing mechanical linkages, the theory and procedures are generally the same. 

The state of a satellite is "a set of parameters required to predict future motion of the system"\cite{tapley2004statistical}. These parameters include the position and velocity vectors of the satellite, and often includes other information relating to the dynamical model. Other information can include atmospheric drag, solar wind, gravity terms, tracking station information, or other system dynamics. Fundamentally, anything can be included in the state that the operator would wish to track and model. 

The process of determining a satellite state at a given Epoch involves convolving information about its present and past state, in a mathematically optimized manner. Present state information comes from both physical observations of the system, as well as from a dynamical system model. Observations often comes from range, range-rate, azimuth, elevation, angel, and other physically observable quantities, provided by tracking ground station or other celestial bodies. The dynamical model is a purely mathematical approximation of the satellite's state in time. Information about the satellite's past state (\emph{a-priori}) information) comes from the navigator's historical data. 

Important to note is the fact that all information about the state is imperfect. Observations have biases and accuracy in measurements, any model will have errors and unknown factors at play, and \emph{a-priori} information is a result of similar imperfections obtained from past information. Basically, the true state of the satellite is never known. The OD process is one which uses all of the imperfect information to generate a statistical "best" estimate of the satellite state at a given epoch. 

Another key note is that the relation between observation of the state and the state itself are highly nonlinear in most applications. 


%----------------------------------------------------
%----------------------------------------------------
%Linearization----------------------------------------------------------


\subsubsection{Linearization}
\label{sec:OD sub Linearization}
One of the most crucial elements of the OD process is the ability to model it in a linear manner, even when both the dynamics and observation relationships are highly nonlinear. Typical OD problems can be formulated in the following manner \cite{tapley2004statistical}. 

\begin{equation}
	\dot{X} = F(X,t), \hspace{0.5cm}     X(t_k) \equiv X_k
	\label{eq:FX}
\end{equation}
	
\begin{equation}
	Y_i = G(X_i,t_i) + \epsilon_i ; \hspace{0.5cm}   i=1,2,...\ell
	\label{eq:Yi}
\end{equation}

$X_k$ is the \emph{n}-dimensional state vector we wish to track at time $t_k$, and  $Y_i$ the observation set used to obtain the best estimate of the state at a given time. In this problem, the system is comprised of indirect observations of a satellite state, with inherent observation errors and biases, and a nonlinear mapping between the state and observation vector. The problem of using said nonlinear observation maps to determine the state with nonlinear dynamics at a given time is very difficult one. 

The key in this OD process comes at this point. If the state $X$, and the reference state $X^*$ (obtained from numerical integration) can be assumed to be reasonably close during the time under examination, the deviation between the two states can be assumed linear. This involves setting a Taylor Series expansion of the true state about the reference state, and neglecting higher order terms. Upon doing so, the full nonlinear OD problem is simplified into solving for the \emph{state deviation vector}, $x$, which involves solving a simpler set of time-dependent ODEs. In this, the problem of estimating an orbit's trajectory and properties at a point in time becomes one in which we find the deviation of the observed trajectory from a reference one. For a fuller explanation of this procedure, reference the textbook \cite[section 4.2]{tapley2004statistical}.

As a result of the linearization, the OD problem described in \eqref{eq:FX} and \eqref{eq:Yi} becomes a simpler one . 

\begin{equation}
	\dot{x}(t) = A(t)x(t)
	\label{eq:x lin}
\end{equation}

\begin{equation}
	y_i = \tilde{H}_ix_i + \epsilon_i ;     \hspace{0.5cm}   i=1,2,...\ell
	\label{eq:y lin}
\end{equation}

With:

\begin{displaymath}
	A(t) = \brackets{\frac{\partial F(t}{\partial X(t)}}
	\hspace{0.5cm}
	\tilde{H}_i = \brackets{\frac{\partial G}{\partial X}}
\end{displaymath}

The $A$ and $\tilde{H}$ matrices are critical in the solving of the OD problem. They are a result of the linearization process. This paper will discuss how to find these specifically \bad{later}. 

In general, it can be seen that $A$ is found by taking the partial derivative $\frac{\partial{F}}{\partial{X}}$. Which is the partial of the system's dynamical model with respect to the system state. In essence, this describes how the system's dynamics change as the state changes itself. The fact that this is a linear relation for most well formulated problems is what allows the OD problem to be solved in the way we do. 
In the same way, $\tilde{H}$ is found by taking the partial derivative $\frac{\partial{G}}{\partial{X}}$. $G$ is the relationship between the satellite state and its observations. This partial represents how the state-observation relation changes with changes in the state. Again, this partial assumes the deviations are linear over the time in question. This holds true for well formulated problems. 


%----------------------------------------------------
%----------------------------------------------------
%State Transition Matrix-----------------------------------------------------


\subsubsection{State Transition Matrix}
\label{sec:OD sub STM}

Equation \eqref{eq:x lin} is a linear system of equations with time-dependent terms. A general solution to this system is presented as \cite{tapley2004statistical}: 

\begin{equation}
	x(t) = \Phi(t,t_k)x_k
	\label{eq:x Phi}
\end{equation}

This equation presents $\Phi$, the \emph{state transition matrix}. This matrix can be used to map the state or state deviation vector forwards and backwards in time. In this general case, it maps $x$ at $t_k$ to $x$ at some arbitrary time $t$. This matrix has several useful and unique properties. All of which are outlined thoroughly in the \emph{5070 textbook}. In summary, these properties lead to the formulation of:

\begin{equation}
	\dot{x}(t) =\dot{ \Phi}(t,t_k)x_k
	\label{eq:xdot Phi}
\end{equation}

Equation \eqref{eq:xdot Phi} is of the same form as \ref{eq:x lin}. That is, it describes a linear set of differentiable equations. In practice, this leads the operator to include a re-formed $\Phi$ with the state vector during numerical integration, giving a numerical solution for the state transition matrix at each state reference time. In practice, a numerical solution for $\Phi$ is all that will be obtained, as an analytical one only arises from conditions such as linearity rarely seen in real operations.

While seeming unnecessary immediately, the state transition matrix is powerful in that it can project the state or state deviation forwards or backwards in time. Often times, an OD filter must be iterated; a process in which observations and state information must be related to some epoch time. The state transition matrix is one of the simplest ways to perform this mapping. 

For example, to map all observations back to a reference epoch at $t_k$, equation \eqref{eq:y lin} may be formulated as:

\begin{eqnarray}
	y_1 = \tilde{H}_1 \Phi(t_1,t_k) x_k + \epsilon_1				\nonumber	\\
	y_2 = \tilde{H}_2 \Phi(t_2,t_k) x_k + \epsilon_2							\\
	\vdots											\nonumber	\\
	y_\ell = \tilde{H}_\ell \Phi(t_\ell,t_k) x_\ell + \epsilon_\ell		\nonumber
\end{eqnarray}

In this, $\ell$ separate observation deviation sets are all mapped to the epoch state deviation vectors at $x_k$. This is desirable for iterative filtering, as well as reducing the number of equations to be solved in the system. 


%----------------------------------------------------
%OD Solutions-------------------------------------------------------------
%----------------------------------------------------
\subsection{OD Solutions}
\label{sec:OD Solutions}
Now, with the formulation of a workable OD problem in section \ref{sec:OD Process}, the statistical 'best' solution must be determined. Conceptually, there are an infinite number of measurable metrics, or \emph{performance indices}, which can be design against. This is one of the most important steps in solving the OD problem. What is the best way to combine an erroneous reference trajectory and noisy/biased observations to obtain an estimate of our state that is closest to the truth trajectory? This simple question is what drives the design of OD filters and determination algorithms. Several of the basic realizations of the answer to this question will be provided here, though there are countless more. 


%----------------------------------------------------
%----------------------------------------------------
%Least Squares----------------------------------------------------

\subsubsection{Least Squares Solution}
\label{OD sub Least Squares}
One of the most common approaches is to attempt to minimize the sum of the squares of the observation residuals. The performance index for this approach is \cite{tapley2004statistical}: 

\begin{equation}
	J(x) = \frac{1}{2 }\epsilon^T \epsilon
	\label{eq:Least Squares}
\end{equation}

Choosing $x$ to minimize eq\eqref{eq:Least Squares} is a natural choice. By design, this procedure is robust to the sign of the residual. If large residuals exist, but have opposite sign, the minimization attempt could yield calculated observation errors of zero. \bad{This method is also sensitive to outliers}.

A solution for $x$ must be found that minimizes the least squares index. From eq\eqref{eq:y lin}, $\epsilon$ may be solved for, and substituted into eq\eqref{eq:Least Squares}. 

\begin{equation}
	J(x) = \frac{1}{2}(y-Hx)^T (y-Hx)
	\label{eq:Min Least Squares}
\end{equation}

Minimizing $J$ is done by finding a zero in its partial derivative, where the second derivative is positive. 

\begin{displaymath}
	\frac{\partial{J}}{\partial{x}} = 0 
	\hspace{0.25cm} Where \hspace{0.25cm}
	\delta{x}^T\frac{\partial{J}^2}{\partial{x}^2} \delta{x}> 0 
\end{displaymath}

After some algebra, a final formulation for $x$ that minimizes the least squares criterion is

\begin{equation}
	\hat{x} = (H^T H)^{-1} H^T y
	\label{eq:x Least Squares}
\end{equation}

By solving for the state deviation vector in this manner, the sum of the square of the observation residuals is minimized. A full derivation of this solution can be found in the \emph{5070 textbook} \cite{tapley2004statistical}. While this is a sufficient measure for some applications, more powerful realizations exist which can help obtain a more accurate prediction of the satellite. 


%----------------------------------------------------
%----------------------------------------------------
%Weighted Least Squares-----------------------
\subsubsection{Weighted Least Squares}
\label{OD sub WLS}
The standard least squares formulation can be modified by adding weighting to each observation vector. In reality, not all observations have equal precision or accuracy, and the circumstances surrounding the observation may cause certainty to change. For example, a laser range finder will obtain more precise results as the satellite flies directly overhead, as opposed to near the horizon, where atmospheric turbulence will distort measurements. With the inclusion of a weighting matrix, eq\eqref{eq:Least Squares} becomes

\begin{equation}
	J(x) = \frac{1}{2}\epsilon^T W \epsilon
	\label{eq: J WLS}
\end{equation}

$W$ is a diagonal weighting matrix, with size $\ell x \ell$. Each diagonal element corresponds to a weighting value to be applied to observation vector. After more algebra, the solution found in eq\eqref{eq:x Least Squares} with weighting included becomes

\begin{equation}
	\hat{x} = (H^TW  H)^{-1} H^T W y
	\label{eq:x WLS}
\end{equation}

The implications of this are the same. By determining $\hat{x}$ in this manner, we wish to minimize a performance criteria which now includes weighting factors.


%----------------------------------------------------
%----------------------------------------------------
%Weighted Least Squares + a-priori-----------------------
\subsubsection{Weighted Least Squares with \emph{a-priori}}
\label{OD sub WLSap}
In the same vein as adding a weighting to the least squares solution, an even better state deviation estimate can be found by including information about the state's history, known as \emph{a-priori} information. This information comes in the form of $\bar{x}$, the last known state deviation vector, and $\bar{W}$, the associated previous weighting matrix associated with that state. When these terms are added into the weighted least squares solution, eq\eqref{eq:x WLS} becomes


\begin{equation}
	\hat{x} = (H^TW  H + \bar{W}_k)^{-1}  (H^T W y + \bar{W}_k   \bar{x}_k)
	\label{eq:x WLSap}
\end{equation}

This solution now takes advantage of the most commonly available information about a given state/state deviation vector. With it, comes the most accurate estimate for $\hat{x}$ that has been discussed yet. 

%----------------------------------------------------
%----------------------------------------------------
%Minimum Variance----------------------
\subsubsection{Minimum Variance Estimate}
\label{OD sub MinVar}
All above formulations of the least squares solutions makes intuitive sense when considering the physical system, however, they lack in the fact that they do not account for statistical characteristics in observation errors and \emph{a-priori} information. One other common estimator is the \emph{Minimum Variance} estimator. This method tries to utilize any statistical information about observations in time to generate the optimal estimate of $\hat{x}$. The derivation of this method won't be explored, but it is in the course textbook. 

\begin{equation}
	\hat{x} = P_k H^T R^{-1} y
	\label{eq:x MinVar}
\end{equation}

Where

\begin{displaymath}
	P = E[(\hat{x}_k - x_k)(\hat{x}_k - x_k)^T]
	\hspace{1cm}
	R=E[\epsilon \epsilon^T] = W^{-1}
\end{displaymath}


$P$ is the system's covariance matrix. It holds the variances (certainty) of each state element on its diagonal, and the of diagonal elements contain the linear correlation factors between state elements. It is a symmetric, positive definite matrix by definition (when properly conditioned), and is a crucial statistical measure of a filter's certainty in its solution at a given time. \bad{$R$ is a matrix which holds information about the observation errors, and their relation to each-other. }

Again, adding \emph{a-priori} information to eq\eqref{eq:x MinVar} can help to yield a more robust estimation.

\begin{equation}
	\hat{x} = (\tilde{H}_k R^{-1} \tilde{H}_k + \bar{P}_k^{-1})^{-1}   (\tilde{H}_k R^{-1} y_k + \bar{P}_k^{-1} \bar{x}_k)
	\label{eq:x MinVarap}
\end{equation}

Theoretically, there are an infinite number of \emph{best} estimate solutions. From a 'least cubed' or 'least 4/3' estimates, to an often used \emph{Maximum Likelihood and Bayesian Estimation} solution, there are dozens of implemented and derived OD solutions. The general process is to first pick a performance index, $J(x)$. This should be a function which has some basis in statistical reasoning. Next, solve for a value of $x$ which minimizes the performance index. 


%----------------------------------------------------
%OD Filters-------------------------------------------------------------
%----------------------------------------------------


\subsection{Orbit Determination Filters} 
\label{sec:Filters}
With assumptions about the linearity of the deviation between satellite truth and reference states, and statistically derived criteria for solving for this state deviation, the process of orbit determination can begin. There are several standard approaches to solving the OD problem. This paper will only concern itself with the basic ones.  

%----------------------------------------------------
%----------------------------------------------------
%Batch Processor----------------------

\subsubsection{The Batch Processor}
\label{sec:Batch Processor}
The Batch Processor is one formulation of the OD process. As the name implies, its aim is to process a set of observations and a reference trajectory at one time, in a single batch computation. Typically, the entire batch of computation is done in order to get a new best estimate for the state deviation vector at an epoch $t_0$. In operation, the satellite's current trajectory is not the only state of interest. For science missions, a very accurate estimation of the state at a given historical instance is needed for high quality analysis of data. The batch processor takes information about a time before the epoch of interest, and information afterwards to generate the best estimate of the satellite state at epoch. 
Using the weighted least squares with \emph{a-priori} information, the eq\eqref{eq:x WLSap} equation for the state deviation vector for a full batch of observations becomes

\begin{equation}
	\hat{x}_0 = (H^T R^{-1} H + \bar{P}_0^{-1})^{-1}   (H^T R^{-1} y + \bar{P}_0^{-1} \bar{x}_0)
	\label{eq:x Batch}
\end{equation}

Here, $t_0$ is the epoch time of interest. Since eq\eqref{eq:x Batch} is supposed to solve for $\hat{x}_0$, all quantities must be mapped to that epoch using the state transition matrices, described in section \ref{sec:OD sub STM}.

The course text book features an in-depth procedure for using the batch processor in an application, as well as insights into key terms and quantities in Chapter 4.7. It will not be discussed here for the sake of brevity. The general process is to \cite{5070LEC}:

\begin{itemize}
	\renewcommand{\labelitemi}{$\bullet$}
	\item Collect Observations and Residuals Over an  Arc
	\item Process All Using Weighted Least Squares with \emph{a-priori}
	\item Generate Best Estimate
	\item Iterate
\end{itemize}


The batch processor will yield an updated result for the state deviation vector at epoch, however it must be iterated in order to obtain the absolute best solution. The iteration process is straightforward, and is done by re-running the filter after updating the initial conditions with the new best estimates. Again, this process is outlined in the textbook. 

One problem with the batch processor is the fact that a large matrix inversion is required. This is evident in eq\eqref{eq:x Batch}, and this portion is called the \emph{information matrix}, eq\eqref{eq:Information Matrix}. In practice, Cholesky decompositions or other methods would be utilized to increase the accuracy of this inversion, but matrix inversions are still computationally heavy. 

\begin{equation}
	\Lambda_0 = (H^T R^{-1} H + \bar{P}_0^{-1})
	\label{eq:Information Matrix}
\end{equation}


The other potential detriment to the batch processor is the fact that since it uses future information to get the best estimate of some past epoch, it is not ideally suited for live tracking situations. This is where the sequential processor comes in. 



%----------------------------------------------------
%----------------------------------------------------
%Kalman Filter----------------------

\subsubsection{Sequential Filter}
\label{sec:Sequential Filter}

The conventional sequential filter, commonly referred to as a Kalman filter, KF, or CKF, is a reformulation of the batch processor described in \ref{sec:Batch Processor}. With perfect numerical precision, the two yield identical results. 

The advantage of the CKF is that it processes observations live. As soon as a new observation is available, it will be processed. The other advantage is that not only can it process observation sets one at a time, but it can process just single observations sequentially. Even when a set is observed at the same time. This is advantageous because it cuts down on computational requirements by just involving scalar divisions~\cite{tapley2004statistical}. The reformulation of the batch solution is as follows

\begin{equation}
	\hat{x}_k = \bar{x}_k + K_k [ y_k - \tilde{H}_k \bar{x}k ]
	\label{eq:x Kalman}
\end{equation}

Where the covariance matrix, $P$ at new time $t_k$ is

\begin{equation}
	P_k = [I - K_k \tilde{H}_k] \bar{P}_k
	\label{eq:P Kalman}
\end{equation}

And $K$ is found at each observation time as

\begin{equation}
	K_k \equiv \bar{P}_k \tilde{H}_k^T [ \tilde{H}_k \bar{P}_k \tilde{H}_k^T + R_k]^{-1}
	\label{eq:K Kalman}
\end{equation}

$K$ is referred to as the Kalman Gain. It is a matrix which weighs the certainty of the observations against the certainty of the reference trajectory. Equation \eqref{eq:x Kalman} shows the computation of the best estimate state deviation vector at time $t_k$. It is a balance between the \emph{a-priori} state deviation vector and the newly observed difference in observed and computed observation deviation vectors. The \emph{balancing} is performed by the Kalman gain. The computation uses weighting, as well as \emph{a-priori} information. 

As with the batch processor, the CKF should be iterated to obtain the best solution. Instead of computing the state deviation at the epoch time, here it is computed at the latest update time. To iterate, this solution must be mapped back to the epoch time using the state transition matrix (section \ref{sec:OD sub STM}).

The full procedural outline is found in Chapter 4.7 of the textbook, but is summarized here.


\begin{itemize}
	\renewcommand{\labelitemi}{$\bullet$}
	\item Collect Observations and Residuals Over an  Arc
	\item Process All Using Weighted Least Squares with \emph{a-priori}
	\item Generate Best Estimate
	\item Iterate
\end{itemize}




%----------------------------------------------------------------------------------------------------------------------------------------



\section{My system}








\newpage
\bibliographystyle{abbrv}
\bibliography{report}

%# To get citations to work, I had to run:
%>>>pdflatex ASEN5070Project.tex'
%twice from command line. Don't know why.... but it works out
%
%But I fixed it in the preferences!!! Preview-->Bibtex-->number of runs:2. Why is this?





\end{document}